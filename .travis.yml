sudo: true

# Use node_js environnement
language: generic

# Cache Gcloud SDK between commands
cache:
  directories:
    - "$HOME/google-cloud-sdk/"

# Install services
services:
  - docker
  - go

# Set env vars
env:
  global:
    - GOOGLE_APPLICATION_CREDENTIALS=~/gcloud-service-key.json


jobs:
  include:
    - stage: master
      if: branch = master 
      script:
        # Install hub
        - sudo wget https://github.com/github/hub/releases/download/v2.6.0/hub-linux-amd64-2.6.0.tgz
        - tar -xzf hub-linux-amd64-2.6.0.tgz
        - sudo cp hub-linux-amd64-2.6.0/bin/hub /bin/
        # Create K8s cluster
        - if [ ! -d "$HOME/google-cloud-sdk/bin" ]; then rm -rf $HOME/google-cloud-sdk; export CLOUDSDK_CORE_DISABLE_PROMPTS=1; curl https://sdk.cloud.google.com | bash; fi
        - source /home/travis/google-cloud-sdk/path.bash.inc
        - gcloud --quiet version
        - gcloud --quiet components update
        - gcloud --quiet components update kubectl
        - echo $GCLOUD_SERVICE_KEY | base64 --decode -i > ${HOME}/gcloud-service-key.json
        - gcloud auth activate-service-account --key-file ${HOME}/gcloud-service-key.json
        - gcloud --quiet config set project $PROJECT_NAME
        - gcloud --quiet config set container/cluster $CLUSTER_NAME
        - gcloud --quiet config set compute/zone ${CLOUDSDK_COMPUTE_ZONE}
        - gcloud container --project $PROJECT_NAME clusters create $CLUSTER_NAME --zone $CLOUDSDK_COMPUTE_ZONE --username "admin" --cluster-version "1.11.6-gke.2" --machine-type "n1-standard-8" --image-type "UBUNTU" --disk-type "pd-standard" --disk-size "100" --scopes "https://www.googleapis.com/auth/devstorage.read_only","https://www.googleapis.com/auth/logging.write","https://www.googleapis.com/auth/monitoring","https://www.googleapis.com/auth/servicecontrol","https://www.googleapis.com/auth/service.management.readonly","https://www.googleapis.com/auth/trace.append" --num-nodes "2" --enable-cloud-logging --enable-cloud-monitoring --no-enable-ip-alias --network "projects/sai-research/global/networks/default" --subnetwork "projects/sai-research/regions/$CLOUDSDK_REGION/subnetworks/default" --addons HorizontalPodAutoscaling,HttpLoadBalancing --no-enable-autoupgrade --no-enable-autorepair
        - gcloud container clusters get-credentials $CLUSTER_NAME --zone $CLOUDSDK_COMPUTE_ZONE --project $PROJECT_NAME
        - kubectl config view
        - set +e

        # Install sed
        - sudo apt install --reinstall sed
        
        # Run scripts in ~/keptn/install/scripts
        - cd install/scripts
        - ./forkGitHubRepositories.sh $GITHUB_ORG

        - cat ./creds.sav |sed 's~DYNATRACE_TENANT_PLACEHOLDER~'"$DT_TENANT"'~' |sed 's~DYNATRACE_API_TOKEN~'"$DT_API_TOKEN"'~' |sed 's~DYNATRACE_PAAS_TOKEN~'"$DT_PAAS_TOKEN"'~' |sed 's~GITHUB_USER_NAME_PLACEHOLDER~'"$GITHUB_USER_NAME"'~' |sed 's~PERSONAL_ACCESS_TOKEN_PLACEHOLDER~'"$GITHUB_TOKEN"'~' |sed 's~GITHUB_USER_EMAIL_PLACEHOLDER~'"$GITHUB_EMAIL"'~' |sed 's~GITHUB_ORG_PLACEHOLDER~'"$GITHUB_ORG"'~' >> creds.json
        - ./setupInfrastructure.sh
        
        # Test front-end keptn v.0.1
        #- export FRONT_END_DEV=$(kubectl describe svc front-end -n dev | grep "LoadBalancer Ingress:" | sed 's~LoadBalancer Ingress:[ \t]*~~')
        #- export FRONT_END_STAGING=$(kubectl describe svc front-end -n staging | grep "LoadBalancer Ingress:" | sed 's~LoadBalancer Ingress:[ \t]*~~')
        #- export FRONT_END_PRODUCTION=$(kubectl describe svc front-end -n production | grep "LoadBalancer Ingress:" | sed 's~LoadBalancer Ingress:[ \t]*~~')
        
        - export ISTIO_INGRESS=$(kubectl describe svc istio-ingressgateway -n istio-system | grep "LoadBalancer Ingress:" | sed 's~LoadBalancer Ingress:[ \t]*~~')
        
        - export EVENT_BROKER_NAME=$(kubectl describe ksvc event-broker -n keptn | grep -m 1 "Name:" | sed 's~Name:[ \t]*~~')
        - ./../../test/assertEquals.sh $EVENT_BROKER_NAME event-broker
        
        #- cat ../test/keptn.postman_environment.json |sed 's~FRONT_END_DEV_PLACEHOLDER~'"$FRONT_END_DEV"'~' |sed 's~FRONT_END_STAGING_PLACEHOLDER~'"$FRONT_END_STAGING"'~' |sed 's~FRONT_END_PRODUCTION_PLACEHOLDER~'"$FRONT_END_PRODUCTION"'~' |sed 's~ISTIO_INGRESS_PLACEHOLDER~'"$ISTIO_INGRESS"'~' >> ../test/env.json
        #- npm install newman
        #- node_modules/.bin/newman run ../test/keptn.postman_collection.json -e ../test/env.json
        
        # Clean up cluster
        #- ./cleanupCluster.sh

        # Delete K8s cluster
        - gcloud container clusters delete $CLUSTER_NAME --zone $CLOUDSDK_COMPUTE_ZONE --project $PROJECT_NAME --quiet

    - stage: pr
      if: type = pull_request
      script:
        - if [ ! -d "$HOME/google-cloud-sdk/bin" ]; then rm -rf $HOME/google-cloud-sdk; export CLOUDSDK_CORE_DISABLE_PROMPTS=1; curl https://sdk.cloud.google.com | bash; fi
        - source /home/travis/google-cloud-sdk/path.bash.inc
        - gcloud --quiet version
        - gcloud --quiet components update
        - gcloud --quiet components update kubectl
        - echo $GCLOUD_SERVICE_KEY | base64 --decode -i > ${HOME}/gcloud-service-key.json
        - gcloud auth activate-service-account --key-file ${HOME}/gcloud-service-key.json
        - gcloud container clusters get-credentials keptn-pr-statuscheck --zone us-central1-a --project sai-research
        - export GCLOUD_USER=$(gcloud config get-value account)
        - kubectl create clusterrolebinding travis-cluster-admin-binding --clusterrole=cluster-admin --user=$GCLOUD_USER
        - export REGISTRY_URL=$(kubectl describe svc docker-registry -n cicd | grep "IP:" | sed 's~IP:[ \t]*~~')
        - cd ./install/scripts/
        - ./setupKnative.sh $JENKINS_USER $JENKINS_PASSWORD $REGISTRY_URL
        - export EVENT_BROKER_NAME=$(kubectl describe ksvc event-broker -n keptn | grep -m 1 "Name:" | sed 's~Name:[ \t]*~~')
        - ./../../test/assertEquals.sh $EVENT_BROKER_NAME event-broker
        # execute GO tests
        - cd ../../cli/ 
        - go test ${gobuild_args} ./...

      after_script:
        - sleep 30
        - kubectl delete pods,svc,deployments --all -n keptn
        - kubectl delete channel --all -n keptn
        - kubectl delete clusterchannelprovisioner --all -n keptn
        - kubectl delete ns knative-build knative-eventing knative-monitoring knative-serving knative-sources
        - kubectl delete clusterrolebinding travis-cluster-admin-binding
